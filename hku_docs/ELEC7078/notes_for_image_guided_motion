1) bringup task 7:
   VRC_CHEATS_ENABLED=1 roslaunch drcsim_gazebo drc_practice_task_7.launch
   wait for Atlas to lower and stand
   (this is best to do in the drcsim release, since Atlas falls down in the pre-release launch)

2) move Atlas in front of valve wall
   select the up/down/left/right icon in the menu bar of the Gazebo display
   click on Atlas in the Gazebo display
   drag him to a location in front of the valve wall such that a valve is reachable
   click on the arrow icon on the menu bar of the Gazebo display, so you don't accidentally move Atlas again

3) pin the torso:
  rostopic pub --once /atlas/mode std_msgs/String '{data: "pinned_with_gravity"}'

4) bring up rviz: 
  add robot model, 
  select "utorso" as the "fixed frame"
  add pointcloud2 from rhand camera
  under the pointCloud2 entry (left panel of rviz), choose the "topic" from the dropdown to be:
    multisense_sl/camera/points2

5) start low-level jnt ctlr: 
   rosrun lowLevelJointServoV2 lowLevelJointServoV2
    (this is the experimental version, to be made consistent with physical Atlas, 
      and which uses gravity-load estimates and inertia estimates from separate publishers)

6) start the gravity-load publisher node:
 rosrun mass_calcs stand_torque_calc  

7) start the inertia calculator/publisher:
   rosrun mass_calcs H_calc

8) start the hand grasp-frame publisher: 
   rosrun grasp_tf grasp_tf_node
    publishes frames l_grasp and r_grasp to tf

----to pre-position the robot using the behavior server:
9) start the behavior server:
   rosrun behavior_server behavior_server

10) run a playfile to pre-position the robot near to grasping a valve, e.g.:
  cd to: elec7078/rosbuild/elec7078_newman/traj_files, and:
  rosrun play_file play_file prep_valve_grab.traj

---optional components----

11) if published jacobians are used, start the jacobian publisher:
   rosrun jacobian_publisher jacobian_publisher

12) optionally, start the LIDAR spinning:
  rostopic pub --once /multisense_sl/set_spindle_speed std_msgs/Float64 '{data: 3.0}'

----point-cloud GUI interface---
13) from package in: /rosbuild/perception_stack/point_cloud_HMI
  rosrun point_cloud_HMI point_cloud_HMI /multisense_sl/points2/color_points:=/multisense_sl/camera/points2
  hover over graphical window
  may expand;
  click-drag over a region of interest; will ignore red (invalid) pts and compute centroid of valid 3-D pts in range
  publishes result to: pickedPointPub = nh_handGoal.advertise<geometry_msgs::PointStamped>("userPickedPoint",1);



14) in rosbuild/elec7078_newman/hand_eye_coord:
  rosrun hand_eye_coord hand_eye_coord


  Now, when you click and drag to select a group of 3-D points, you should see a response in two windows:
   the window from which point_cloud_HMI was run, as well as the window from which hand_eye_coord was run
  Note: the interactive image updates only after a click.  If it gets too "old", the points will not transform.
    you can update the image by clicking in a red region.  This will not try to send a valid point, but it will 
    update the scene

Some compiler tricks:

hku_clean
hku_make (compiles the entire team code)
hku_make -d package_name  (faster, for compiling just one package)

If a window does not recognize ros package paths, do this:
cd ~/ros_workspace/repository_name
source catkin/devel/setup.sh
export ROS_WORKSPACE=`pwd`
export ROS_PACKAGE_PATH=$ROS_WORKSPACE:$ROS_PACKAGE_PATH



